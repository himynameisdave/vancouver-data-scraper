name: 🐶 Lost pets

permissions:
  contents: write

on:
  push:
  workflow_dispatch:
  schedule:
    # Run twice a day at 7am and 7pm Pacific Time
    # Offset to slightly off the hour, so that not all of these scrapers are running at the same time.
    - cron: '3 15 * * *'
    - cron: '3 3 * * *'

jobs:
  scheduled:
    runs-on: ubuntu-latest
    # This ensures that at most only one can be run at a time
    concurrency:
      group: scrape-vancouver-data
      cancel-in-progress: false
    steps:
    - name: Check out this repo
      uses: actions/checkout@v4

    - name: Fetch latest data
      run: |-
        curl "https://opendata.vancouver.ca/api/explore/v2.1/catalog/datasets/animal-control-inventory-lost-and-found/exports/json?lang=en&timezone=America%2FLos_Angeles" | jq . > ./data/lost-pets.json

    - name: Commit and push if it changed
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "🐶 Latest lost pets data: ${timestamp}" || exit 0
        git pull --rebase origin main
        git push
